{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Enrolment Data Cleaning Project\n",
                "This notebook covers the step-by-step process of cleaning and merging three enrolment datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Import required libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "print(\"Libraries imported successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Define Cleaning Rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# State Mapping Dictionary\n",
                "state_corrections = {\n",
                "    '100000': None,  # Will be dropped\n",
                "    'Andaman & Nicobar Islands': 'Andaman and Nicobar Islands',\n",
                "    'Dadra & Nagar Haveli': 'Dadra and Nagar Haveli and Daman and Diu',\n",
                "    'Dadra and Nagar Haveli': 'Dadra and Nagar Haveli and Daman and Diu',\n",
                "    'Daman & Diu': 'Dadra and Nagar Haveli and Daman and Diu',\n",
                "    'Daman and Diu': 'Dadra and Nagar Haveli and Daman and Diu',\n",
                "    'The Dadra And Nagar Haveli And Daman And Diu': 'Dadra and Nagar Haveli and Daman and Diu',\n",
                "    'Jammu & Kashmir': 'Jammu and Kashmir',\n",
                "    'Jammu And Kashmir': 'Jammu and Kashmir',\n",
                "    'ODISHA': 'Odisha',\n",
                "    'Orissa': 'Odisha',\n",
                "    'Pondicherry': 'Puducherry',\n",
                "    'WEST BENGAL': 'West Bengal',\n",
                "    'WESTBENGAL': 'West Bengal',\n",
                "    'West  Bengal': 'West Bengal',\n",
                "    'West Bangal': 'West Bengal',\n",
                "    'West bengal': 'West Bengal',\n",
                "    'Westbengal': 'West Bengal',\n",
                "    'andhra pradesh': 'Andhra Pradesh'\n",
                "}\n",
                "\n",
                "# District Mapping Dictionary\n",
                "district_corrections = {\n",
                "    # Remove special chars and standardize\n",
                "    'Bagalkot *': 'Bagalkot',\n",
                "    'Chamarajanagar *': 'Chamarajanagar',\n",
                "    'Chamrajnagar': 'Chamarajanagar',\n",
                "    'Chickmagalur': 'Chikkamagaluru',\n",
                "    'Chikmagalur': 'Chikkamagaluru',\n",
                "    'Chikkamagaluru': 'Chikkamagaluru',\n",
                "    'Davangere': 'Davanagere',\n",
                "    'Hasan': 'Hassan',\n",
                "    'Haveri *': 'Haveri',\n",
                "    'Ramanagar': 'Ramanagara',\n",
                "    'Tumkur': 'Tumakuru',\n",
                "    'Bagpat': 'Baghpat',\n",
                "    'Bulandshahar': 'Bulandshahr',\n",
                "    'Kushinagar *': 'Kushinagar',\n",
                "    'Kushi Nagar': 'Kushinagar',\n",
                "    'Mahrajganj': 'Maharajganj',\n",
                "    'Shrawasti': 'Shravasti',\n",
                "    'Siddharth Nagar': 'Siddharthnagar',\n",
                "    'Aurangabad(BH)': 'Aurangabad',\n",
                "    'Aurangabad(bh)': 'Aurangabad',\n",
                "    'Purba Champaran': 'East Champaran',\n",
                "    'Purbi Champaran': 'East Champaran',\n",
                "    'Samstipur': 'Samastipur',\n",
                "    'Sheikpura': 'Sheikhpura',\n",
                "    'Ahmed Nagar': 'Ahmednagar',\n",
                "    'Ahmadnagar': 'Ahmednagar',\n",
                "    'Buldhana': 'Buldana',\n",
                "    'Chatrapati Sambhaji Nagar': 'Chhatrapati Sambhajinagar',\n",
                "    'Gondiya': 'Gondia',\n",
                "    'Gondiya *': 'Gondia',\n",
                "    'Hingoli *': 'Hingoli',\n",
                "    'Nandurbar *': 'Nandurbar',\n",
                "    'Washim *': 'Washim',\n",
                "    'Jhajjar *': 'Jhajjar',\n",
                "    'Yamuna Nagar': 'Yamunanagar',\n",
                "    'Chittaurgarh': 'Chittorgarh',\n",
                "    'Deeg\\xa0': 'Deeg',\n",
                "    'Jalore': 'Jalor',\n",
                "    'Jhunjhunun': 'Jhunjhunu',\n",
                "    'S.A.S Nagar(Mohali)': 'SAS Nagar (Mohali)',\n",
                "    'Ashok Nagar': 'Ashoknagar',\n",
                "    '24 Paraganas North': 'North 24 Parganas',\n",
                "    'North Twenty Four Parganas': 'North 24 Parganas',\n",
                "    'Barddhaman': 'Bardhaman',\n",
                "    'Cooch Behar': 'Coochbehar',\n",
                "    'East Midnapur': 'East Midnapore',\n",
                "    'Hooghiy': 'Hooghly',\n",
                "    'Maldah': 'Malda',\n",
                "    'Puruliya': 'Purulia',\n",
                "    'South 24 Pargana': 'South 24 Parganas',\n",
                "    'South Twenty Four Parganas': 'South 24 Parganas',\n",
                "    'hooghly': 'Hooghly',\n",
                "    'Hardwar': 'Haridwar',\n",
                "    'Ahmadabad': 'Ahmedabad',\n",
                "    'Banas Kantha': 'Banaskantha',\n",
                "    'Panch Mahals': 'Panchmahals',\n",
                "    'Sabar Kantha': 'Sabarkantha',\n",
                "    'Surendra Nagar': 'Surendranagar',\n",
                "    'Ananthapur': 'Anantapur',\n",
                "    'Ananthapuramu': 'Anantapur',\n",
                "    'chittoor': 'Chittoor',\n",
                "    'K.V.Rangareddy': 'Rangareddy',\n",
                "    'K.v. Rangareddy': 'Rangareddy',\n",
                "    'Karim Nagar': 'Karimnagar',\n",
                "    'Mahabub Nagar': 'Mahabubnagar',\n",
                "    'Mahbubnagar': 'Mahabubnagar',\n",
                "    'rangareddi': 'Rangareddy',\n",
                "    'Visakhapatanam': 'Visakhapatnam',\n",
                "    'Kancheepuram': 'Kanchipuram',\n",
                "    'Kanniyakumari': 'Kanyakumari',\n",
                "    'Thiruvallur': 'Tiruvallur',\n",
                "    'Tirupathur': 'Tirupattur',\n",
                "    'Tiruvarur': 'Thiruvarur',\n",
                "    'Villupuram': 'Viluppuram',\n",
                "    'Janjgir - Champa': 'Janjgir Champa',\n",
                "    'Janjgir-champa': 'Janjgir Champa',\n",
                "    'Mohalla-Manpur-Ambagarh Chowki': 'Mohla-Manpur-Ambagarh Chowki',\n",
                "    'Bokaro *': 'Bokaro',\n",
                "    'East Singhbum': 'East Singhbhum',\n",
                "    'Garhwa *': 'Garhwa',\n",
                "    'Hazaribag': 'Hazaribagh',\n",
                "    'Koderma': 'Kodarma',\n",
                "    'Pakaur': 'Pakur',\n",
                "    'Palamau': 'Palamu',\n",
                "    'Sahebganj': 'Sahibganj',\n",
                "    'Seraikela-Kharsawan': 'Seraikela Kharsawan',\n",
                "    'Jangoan': 'Jangaon',\n",
                "    'Baramula': 'Baramulla',\n",
                "    'Bandipore': 'Bandipora',\n",
                "    'Badgam': 'Budgam',\n",
                "    'Gurgaon': 'Gurugram',\n",
                "    'Gulbarga': 'Kalaburagi',\n",
                "    'Mysore': 'Mysuru',\n",
                "    'Belgaum': 'Belagavi',\n",
                "    'Bellary': 'Ballari',\n",
                "    'Bijapur': 'Vijayapura',\n",
                "    'Shimoga': 'Shivamogga',\n",
                "\n",
                "    # Chhattisgarh Corrections (Mapping to user's 33 districts)\n",
                "    'Balod': 'Balod',\n",
                "    'Baloda Bazar': 'Baloda Bazar-Bhatapara',\n",
                "    'Baloda Bazar-Bhatapara': 'Baloda Bazar-Bhatapara',\n",
                "    'Balrampur': 'Balrampur',\n",
                "    'Bastar': 'Bastar',\n",
                "    'Bemetara': 'Bemetara',\n",
                "    'Bijapur': 'Bijapur',\n",
                "    'Bilaspur': 'Bilaspur',\n",
                "    'Dantewada': 'Dantewada',\n",
                "    'Dakshin Bastar Dantewada': 'Dantewada',\n",
                "    'Dhamtari': 'Dhamtari',\n",
                "    'Durg': 'Durg',\n",
                "    'Gariaband': 'Gariaband',\n",
                "    'Gaurela-Pendra-Marwahi': 'Gaurela-Pendra-Marwahi',\n",
                "    'Gaurella Pendra Marwahi': 'Gaurela-Pendra-Marwahi',\n",
                "    'Janjgir-Champa': 'Janjgir-Champa',\n",
                "    'Janjgir Champa': 'Janjgir-Champa',\n",
                "    'Janjgir - Champa': 'Janjgir-Champa',\n",
                "    'Jashpur': 'Jashpur',\n",
                "    'Kabirdham': 'Kabirdham (Kawardha)',\n",
                "    'Kabeerdham': 'Kabirdham (Kawardha)',\n",
                "    'Kabirdham': 'Kabirdham (Kawardha)',\n",
                "    'Kanker': 'Kanker',\n",
                "    'Uttar Bastar Kanker': 'Kanker',\n",
                "    'Kondagaon': 'Kondagaon',\n",
                "    'Korba': 'Korba',\n",
                "    'Khairagarh-Chhuikhadan-Gandai': 'Khairagarh-Chhuikhadan-Gandai',\n",
                "    'Rajnandgaon': 'Rajnandgaon',\n",
                "    'Sarangarh-Bilaigarh': 'Sarangarh-Bilaigarh',\n",
                "    'Sakti': 'Sakti',\n",
                "    'Sukma': 'Sukma',\n",
                "    'Surajpur': 'Surajpur',\n",
                "    'Surguja': 'Surguja',\n",
                "    'Ambikapur': 'Surguja', # Ambikapur is HQ of Surguja, data often mixes these\n",
                "    'Raipur': 'Raipur',\n",
                "    'Raigarh': 'Raigarh',\n",
                "    'Mahasamund': 'Mahasamund',\n",
                "    'Korea': 'Koriya (Korea)',\n",
                "    'Koriya': 'Koriya (Korea)',\n",
                "    'Manendragarh-Chirmiri-Bharatpur': 'Manendragarh-Chirmiri-Bharatpur',\n",
                "    'Mohla-Manpur-Ambagarh Chowki': 'Mohla-Manpur-Ambagarh Chowki',\n",
                "    'Mohla Manpur Ambagarh Chowki': 'Mohla-Manpur-Ambagarh Chowki',\n",
                "    'Narayanpur': 'Narayanpur'\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Process Enrolment Data 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "file_path_1 = 'enrol_01.csv'\n",
                "df1 = pd.read_csv(file_path_1)\n",
                "\n",
                "# Find unique states (initial check)\n",
                "print(\"Unique states in Enrol 1 (Before Cleaning):\")\n",
                "print(df1['state'].unique())\n",
                "\n",
                "# Clean null values explicitly for essential columns\n",
                "df1.dropna(subset=['state', 'district'], inplace=True)\n",
                "\n",
                "# Drop duplicates initially\n",
                "df1.drop_duplicates(inplace=True)\n",
                "\n",
                "# Clean State Names\n",
                "df1['cleaned_state'] = df1['state'].replace(state_corrections)\n",
                "df1.dropna(subset=['cleaned_state'], inplace=True)\n",
                "\n",
                "# CLEAN DISTRICT Names -> Create 'new_district' column\n",
                "df1['new_district'] = df1['district'].astype(str).str.strip()\n",
                "df1['new_district'] = df1['new_district'].replace(district_corrections)\n",
                "\n",
                "# Remove empty districts after cleaning\n",
                "df1 = df1[df1['new_district'] != '']\n",
                "df1 = df1[df1['new_district'] != 'nan']\n",
                "\n",
                "# Clean duplicates AGAIN to remove redundant rows created by standardization\n",
                "df1.drop_duplicates(inplace=True)\n",
                "\n",
                "print(\"\\nUnique states in Enrol 1 (After Cleaning):\")\n",
                "print(df1['cleaned_state'].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Process Enrolment Data 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "file_path_2 = 'enrol_02.csv'\n",
                "df2 = pd.read_csv(file_path_2)\n",
                "\n",
                "# Find unique states\n",
                "print(\"Unique states in Enrol 2 (Before Cleaning):\")\n",
                "print(df2['state'].unique())\n",
                "\n",
                "# Clean nulls explicitly\n",
                "df2.dropna(subset=['state', 'district'], inplace=True)\n",
                "\n",
                "# Drop duplicates initially\n",
                "df2.drop_duplicates(inplace=True)\n",
                "\n",
                "# Clean State Names\n",
                "df2['cleaned_state'] = df2['state'].replace(state_corrections)\n",
                "df2.dropna(subset=['cleaned_state'], inplace=True)\n",
                "\n",
                "# CLEAN DISTRICT Names -> Create 'new_district' column\n",
                "df2['new_district'] = df2['district'].astype(str).str.strip()\n",
                "df2['new_district'] = df2['new_district'].replace(district_corrections)\n",
                "\n",
                "# Remove empty districts\n",
                "df2 = df2[df2['new_district'] != '']\n",
                "df2 = df2[df2['new_district'] != 'nan']\n",
                "\n",
                "# Clean duplicates AGAIN\n",
                "df2.drop_duplicates(inplace=True)\n",
                "\n",
                "print(\"\\nUnique states in Enrol 2 (After Cleaning):\")\n",
                "print(df2['cleaned_state'].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Process Enrolment Data 3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "file_path_3 = 'enrol_03.csv'\n",
                "df3 = pd.read_csv(file_path_3)\n",
                "\n",
                "# Find unique states\n",
                "print(\"Unique states in Enrol 3 (Before Cleaning):\")\n",
                "print(df3['state'].unique())\n",
                "\n",
                "# Clean nulls explicitly\n",
                "df3.dropna(subset=['state', 'district'], inplace=True)\n",
                "\n",
                "# Drop duplicates initially\n",
                "df3.drop_duplicates(inplace=True)\n",
                "\n",
                "# Clean State Names\n",
                "df3['cleaned_state'] = df3['state'].replace(state_corrections)\n",
                "df3.dropna(subset=['cleaned_state'], inplace=True)\n",
                "\n",
                "# CLEAN DISTRICT Names -> Create 'new_district' column\n",
                "df3['new_district'] = df3['district'].astype(str).str.strip()\n",
                "df3['new_district'] = df3['new_district'].replace(district_corrections)\n",
                "\n",
                "# Remove empty districts\n",
                "df3 = df3[df3['new_district'] != '']\n",
                "df3 = df3[df3['new_district'] != 'nan']\n",
                "\n",
                "# Clean duplicates AGAIN\n",
                "df3.drop_duplicates(inplace=True)\n",
                "\n",
                "print(\"\\nUnique states in Enrol 3 (After Cleaning):\")\n",
                "print(df3['cleaned_state'].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Merge Datasets and Final Verification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Merge all 3 datasets\n",
                "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
                "\n",
                "print(f\"Merged Dataset Shape: {merged_df.shape}\")\n",
                "\n",
                "# Verify final unique states and districts\n",
                "unique_states = merged_df['cleaned_state'].unique()\n",
                "unique_districts = merged_df['new_district'].unique()\n",
                "print(f\"\\nTotal Unique States: {len(unique_states)}\")\n",
                "print(sorted(unique_states))\n",
                "print(f\"\\nTotal Unique Districts: {len(unique_districts)}\")\n",
                "# print(sorted(unique_districts)) # Corrected list\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Display the Final Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show the first few rows of the merged dataset including the new columns\n",
                "print(\"Top 5 rows of the merged dataset:\")\n",
                "print(merged_df[['date', 'cleaned_state', 'new_district', 'district', 'pincode', 'age_0_5', 'age_5_17', 'age_18_greater']].head())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Define Canonical Chhattisgarh District List"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Canonical list of 33 Chhattisgarh districts\n",
                "chhattisgarh_canonical = [\n",
                "    'Balod',\n",
                "    'Baloda Bazar-Bhatapara',\n",
                "    'Balrampur',\n",
                "    'Bastar',\n",
                "    'Bemetara',\n",
                "    'Bijapur',\n",
                "    'Bilaspur',\n",
                "    'Dantewada',\n",
                "    'Dhamtari',\n",
                "    'Durg',\n",
                "    'Gariaband',\n",
                "    'Gaurela-Pendra-Marwahi',\n",
                "    'Janjgir-Champa',\n",
                "    'Jashpur',\n",
                "    'Kabirdham (Kawardha)',\n",
                "    'Kanker',\n",
                "    'Khairagarh-Chhuikhadan-Gandai',\n",
                "    'Kondagaon',\n",
                "    'Korba',\n",
                "    'Koriya (Korea)',\n",
                "    'Mahasamund',\n",
                "    'Manendragarh-Chirmiri-Bharatpur',\n",
                "    'Mohla-Manpur-Ambagarh Chowki',\n",
                "    'Narayanpur',\n",
                "    'Raigarh',\n",
                "    'Raipur',\n",
                "    'Rajnandgaon',\n",
                "    'Sakti',\n",
                "    'Sarangarh-Bilaigarh',\n",
                "    'Sukma',\n",
                "    'Surajpur',\n",
                "    'Surguja',\n",
                "    'Korea'\n",
                "]\n",
                "\n",
                "print(\"Canonical Chhattisgarh District List defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Chhattisgarh District Verification & Final Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter for Chhattisgarh\n",
                "cg_df = merged_df[merged_df['cleaned_state'] == 'Chhattisgarh']\n",
                "\n",
                "# Verify against canonical list\n",
                "cg_districts = cg_df['new_district'].unique()\n",
                "\n",
                "print(f\"Unique Districts in Chhattisgarh Data ({len(cg_districts)}):\")\n",
                "print(sorted(cg_districts))\n",
                "\n",
                "print(\"\\n--- Verification Against Canonical List ---\")\n",
                "missing = set(chhattisgarh_canonical) - set(cg_districts)\n",
                "extra = set(cg_districts) - set(chhattisgarh_canonical)\n",
                "\n",
                "if not missing and not extra:\n",
                "    print(\"All Chhattisgarh districts map perfectly to your list!\")\n",
                "else:\n",
                "    if missing: print(f\"Missing from data: {sorted(missing)}\")\n",
                "    if extra: print(f\"Extra in data (not in your list): {sorted(extra)}\")\n",
                "\n",
                "print(\"\\n--- Final Table for Chhattisgarh Districts ---\")\n",
                "print(cg_df[['date', 'cleaned_state', 'new_district', 'district', 'pincode', 'age_0_5', 'age_5_17', 'age_18_greater']])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Export Chhattisgarh Data to Excel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to Excel\n",
                "excel_filename = 'chhattisgarh_enrolment_data.xlsx'\n",
                "cg_df.to_excel(excel_filename, index=False)\n",
                "print(f\"Successfully exported Chhattisgarh data to {excel_filename}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 11: Extract Unique Pincodes per District"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Unique Pincodes per District in Chhattisgarh:\")\n",
                "pincode_data = []\n",
                "\n",
                "for district in sorted(chhattisgarh_canonical):\n",
                "    # Using new_district to ensure we check against our standardized names\n",
                "    # Note: Use cg_df which is already filtered for Chhattisgarh\n",
                "    dist_df = cg_df[cg_df['new_district'] == district]\n",
                "    \n",
                "    if dist_df.empty:\n",
                "        print(f\"\\n{district}: No data found.\")\n",
                "        pincode_data.append({'District': district, 'Unique Pincodes': 'No Data', 'Count': 0})\n",
                "        continue\n",
                "\n",
                "    # Clean pincodes\n",
                "    # Ensure numeric validity (basic check)\n",
                "    codes = dist_df['pincode'].dropna().unique()\n",
                "    valid_codes = []\n",
                "    for c in codes:\n",
                "        try:\n",
                "            c_str = str(c).split('.')[0] # handle float 123.0\n",
                "            if c_str.isdigit() and len(c_str) >= 6:\n",
                "                 valid_codes.append(int(c_str))\n",
                "        except:\n",
                "            continue\n",
                "    \n",
                "    valid_codes = sorted(list(set(valid_codes)))\n",
                "    \n",
                "    print(f\"\\n{district} ({len(valid_codes)} pincodes):\")\n",
                "    print(valid_codes)\n",
                "    \n",
                "    pincode_data.append({\n",
                "        'District': district,\n",
                "        'Unique Pincodes': ', '.join(map(str, valid_codes)),\n",
                "        'Count': len(valid_codes)\n",
                "    })\n",
                "\n",
                "# Summary Table\n",
                "pincode_df = pd.DataFrame(pincode_data)\n",
                "print(\"\\n--- Pincode Summary Table ---\")\n",
                "print(pincode_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 12: Detailed Pincode Analysis (Multi-Use Checks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analysis 1: Districts using Multiple Pincodes (List the pincodes for each)\n",
                "print(\"--- Analysis: Districts using Multiple Pincodes ---\")\n",
                "districts_with_multi_pincodes = pincode_df[pincode_df['Count'] > 1]\n",
                "if districts_with_multi_pincodes.empty:\n",
                "     print(\"No districts have more than 1 pincode.\")\n",
                "else:\n",
                "     print(f\"Found {len(districts_with_multi_pincodes)} districts with > 1 pincode.\")\n",
                "\n",
                "# Analysis 2: Pincodes used by Multiple Districts (Inconsistency Check)\n",
                "print(\"\\n--- Analysis: Pincodes used by Multiple Districts (Overlap Check) ---\")\n",
                "cg_df['pincode_clean'] = cg_df['pincode'].apply(lambda x: str(x).split('.')[0] if pd.notnull(x) else np.nan)\n",
                "pincode_counts = cg_df.groupby('pincode_clean')['new_district'].nunique()\n",
                "multi_district_pincodes = pincode_counts[pincode_counts > 1]\n",
                "\n",
                "if multi_district_pincodes.empty:\n",
                "    print(\"SUCCESS: No pincode is shared between different districts.\")\n",
                "else:\n",
                "    print(f\"WARNING: {len(multi_district_pincodes)} pincodes are mapped to multiple districts.\")\n",
                "    print(\"Exporting conflict details to Step 13...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 13: Export Pincode Conflicts to Excel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find conflicting pincodes\n",
                "conflicting_pincodes = multi_district_pincodes.index.tolist()\n",
                "\n",
                "# Filter dataset for these pincodes\n",
                "conflict_df = cg_df[cg_df['pincode_clean'].isin(conflicting_pincodes)]\n",
                "\n",
                "if not conflict_df.empty:\n",
                "    # Sort for easier reading\n",
                "    conflict_df = conflict_df.sort_values(by=['pincode_clean', 'new_district'])\n",
                "    \n",
                "    # Export\n",
                "    conflict_filename = 'chhattisgarh_pincode_conflicts.xlsx'\n",
                "    conflict_df.to_excel(conflict_filename, index=False)\n",
                "    print(f\"Shared/Conflicting pincode details exported to {conflict_filename}\")\n",
                "    print(\"Top 10 rows of conflicts:\")\n",
                "    print(conflict_df[['new_district', 'pincode', 'date']].head(10))\n",
                "else:\n",
                "    print(\"No conflicting pincodes found to export.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 14: Reserved for Previous Summary Logic (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This step is kept as a placeholder if you want the specific single-row summary again, \n",
                "# but the next step (Step 15) provides the detailed breakdown you requested.\n",
                "print(\"Proceeding to Detailed Analysis (Step 15)...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 15: Detailed Conflict Analysis (With State, Formatted Date, and Ages)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Generating Detailed Dominance Analysis (One row per district for shared pincodes)...\")\n",
                "\n",
                "if not multi_district_pincodes.empty:\n",
                "    detailed_data = []\n",
                "    shared_pincodes = multi_district_pincodes.index.tolist()\n",
                "\n",
                "    # Filter main DF for only shared pincodes\n",
                "    all_conflicts = cg_df[cg_df['pincode_clean'].isin(shared_pincodes)]\n",
                "    \n",
                "    # Determine the 'Total Records' per pincode to help with sorting later\n",
                "    pincode_volumes = all_conflicts['pincode_clean'].value_counts().to_dict()\n",
                "\n",
                "    # Iterate through each shared pincode\n",
                "    for pin in shared_pincodes:\n",
                "        pin_df = all_conflicts[all_conflicts['pincode_clean'] == pin]\n",
                "        total_pin_records = len(pin_df)\n",
                "        \n",
                "        # Get unique districts for this pincode\n",
                "        districts = pin_df['new_district'].unique()\n",
                "        \n",
                "        # For each district sharing this pincode, calculate stats\n",
                "        for dist in districts:\n",
                "            dist_rows = pin_df[pin_df['new_district'] == dist]\n",
                "            count = len(dist_rows)\n",
                "            \n",
                "            # Age Sums\n",
                "            age_0_5 = dist_rows['age_0_5'].sum()\n",
                "            age_5_17 = dist_rows['age_5_17'].sum()\n",
                "            age_18_greater = dist_rows['age_18_greater'].sum()\n",
                "            \n",
                "            # Date Analysis (Find Mode and Range)\n",
                "            dates = pd.to_datetime(dist_rows['date'], format='%d-%m-%Y', errors='coerce')\n",
                "            valid_dates = dates.dropna()\n",
                "            \n",
                "            if not valid_dates.empty:\n",
                "                date_mode = valid_dates.mode()[0].strftime('%d-%m-%Y')\n",
                "                month_year = valid_dates.mode()[0].strftime('%B %Y') # e.g. January 2024\n",
                "            else:\n",
                "                date_mode = \"Unknown\"\n",
                "                month_year = \"Unknown\"\n",
                "                \n",
                "            detailed_data.append({\n",
                "                'State': 'Chhattisgarh', # Restored State Column\n",
                "                'Pincode': pin,\n",
                "                'Total Pincode Volume': total_pin_records, # Helper for sorting\n",
                "                'District': dist,\n",
                "                'Record Count': count,\n",
                "                'Age_0_5_Sum': age_0_5,\n",
                "                'Age_5_17_Sum': age_5_17,\n",
                "                'Age_18_Greater_Sum': age_18_greater,\n",
                "                'Representative_Date': date_mode,\n",
                "                'Month_Year': month_year\n",
                "            })\n",
                "            \n",
                "    # Convert to DataFrame\n",
                "    detailed_df = pd.DataFrame(detailed_data)\n",
                "    \n",
                "    # Sorting Logic: \n",
                "    # 1. Primary Sort: Pincode Volume (High to Low) -> Shows biggest conflict groups first\n",
                "    # 2. Secondary Sort: Record Count (High to Low) -> Shows Dominant District first within group\n",
                "    detailed_df = detailed_df.sort_values(by=['Total Pincode Volume', 'Record Count'], ascending=[False, False])\n",
                "    \n",
                "    print(\"Detailed Dominance Table Generated (Top 10 rows):\")\n",
                "    print(detailed_df.head(10))\n",
                "    \n",
                "    # Export\n",
                "    output_file = 'chhattisgarh_detailed_dominance.xlsx'\n",
                "    detailed_df.to_excel(output_file, index=False)\n",
                "    print(f\"\\nDetailed Excel file created at: {output_file}\")\n",
                "\n",
                "else:\n",
                "    print(\"No shared pincodes found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 16: District-wise Enrolment Ranking (Aggregated by Total Ages)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Generating District-wise Enrolment Ranking Table...\")\n",
                "\n",
                "# Group by District\n",
                "district_stats = cg_df.groupby('new_district').agg({\n",
                "    'age_0_5': 'sum',\n",
                "    'age_5_17': 'sum',\n",
                "    'age_18_greater': 'sum'\n",
                "}).reset_index()\n",
                "\n",
                "# Calculate Total Enrolments (Sum of all 3 age categories)\n",
                "district_stats['Total_Enrolment'] = district_stats['age_0_5'] + district_stats['age_5_17'] + district_stats['age_18_greater']\n",
                "\n",
                "# Add Representative Date info for each district (Optional but consistent with prev requests)\n",
                "# Using the Mode date for each district\n",
                "date_modes = cg_df.groupby('new_district')['date'].apply(lambda x: pd.to_datetime(x, format='%d-%m-%Y', errors='coerce').mode()[0].strftime('%d-%m-%Y') \n",
                "                                                       if not pd.to_datetime(x, format='%d-%m-%Y', errors='coerce').mode().empty else 'Unknown')\n",
                "district_stats['Most_Frequent_Date'] = district_stats['new_district'].map(date_modes)\n",
                "\n",
                "# Add State column\n",
                "district_stats.insert(0, 'State', 'Chhattisgarh')\n",
                "\n",
                "# Rename columns for clarity\n",
                "district_stats = district_stats.rename(columns={\n",
                "    'new_district': 'District',\n",
                "    'age_0_5': 'Enrolment_Age_0_5',\n",
                "    'age_5_17': 'Enrolment_Age_5_17',\n",
                "    'age_18_greater': 'Enrolment_Age_18_Plus'\n",
                "})\n",
                "\n",
                "# Sort by Total Enrolment Descending (Highest First)\n",
                "district_stats = district_stats.sort_values(by='Total_Enrolment', ascending=False)\n",
                "\n",
                "print(\"Top 10 Districts by Total Enrolment:\")\n",
                "print(district_stats.head(10))\n",
                "\n",
                "# Export to Excel\n",
                "ranking_filename = 'chhattisgarh_district_ranking.xlsx'\n",
                "district_stats.to_excel(ranking_filename, index=False)\n",
                "print(f\"\\nDistrict Ranking Excel created at: {ranking_filename}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}